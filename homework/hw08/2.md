# Reading: Overfitting and regularization

## Instructions. 

Read Section Overfitting through Regularization in Chapter 11 of our GÃ©ron text, and read Chapter 5 of our Chollet text.  
Answer the following questions by editing file [overfitting.txt](overfitting.txt).  You may need to also refer to lecture slides and the Keras documentation.

## Questions

### Q1
(a/b/c/d)
What is the default value for the Dropout layer in Keras?

a.	0.0

b.	1.0

c.	0.5

d.	there is no default


### Q2
(a/b/c)
A dropout layer in Keras applies to:

a.	the layer immediately before it

b.	the layer immediately after it

c.	all layers after it


### Q3
(a/b/c)
In dropout, some neurons are chosen randomly.  How often does this happen?

a.	once every training step

b.	once every epoch

c.	once for the entire training process


### Q4
(a/b/c)
When is dropout applied?

a.	only during training

b.	only during testing

c.	during both training and testing


### Q5
(a/b)
What is the purpose of dropout?

a.	reduce training time

b.	reduce overfitting


### Q6
Name two Keras layers that support weight regularization arguments.

### Q7
(a/b/c)
Weight regularization causes an additional component to be included in the loss function used during training.  If L2 regularization is used on a layer of a model, this component involves:

a.	the sum of the weights of the layer

b.	the sum of the squared weights of the layer

c.	the sum of the absolute values of the weights of the layer


### Q8
(a/b)
What does increasing the value of the argument to regularizers.l2() in Keras do?

a.	it results in increased regularization

b.	it results in decreased regularization

