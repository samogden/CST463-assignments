{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "kjh9naG9-yTY",
   "metadata": {
    "id": "kjh9naG9-yTY"
   },
   "source": [
    "# CNN architectures for CIFAR-10 classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p4bM3KRo-4lG",
   "metadata": {
    "id": "p4bM3KRo-4lG"
   },
   "source": [
    "CIFAR-10 is a famous collection of small color images, each 32 x 32 pixels.  There are 6,000 images in each of 10 classes.\n",
    "\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "In this assignment you will perform experiments with a CNN model, and then tune the model to obtain the best test accuracy on CIFAR-10.\n",
    "\n",
    "The purpose of the assignment if for you to get a feeling for how changes to a CNN model will affect its performance.  In the \"experiment\" problems, focus on clear, thoughtful, quantitative discussion of the impact of the change to the model.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "In the code below, a baseline CNN classifier is created.  Your job is to code and run a bunch of experiments to see the effect of changes to the CNN classifier. \n",
    "\n",
    "Read the code, and look for problem prompts.  There are 9 problems.\n",
    "\n",
    "vF22.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fefc385",
   "metadata": {
    "id": "2fefc385"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.datasets import mnist, cifar10\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cMIMn9ITWDBF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1665681552411,
     "user": {
      "displayName": "Glenn",
      "userId": "10553525024667050874"
     },
     "user_tz": 420
    },
    "id": "cMIMn9ITWDBF",
    "outputId": "3923ad41-86d1-4e02-fb8f-e5b8a870831b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# allow output to span multiple output lines in the console\n",
    "pd.set_option('display.max_columns', 600)\n",
    "pd.options.display.width = 120\n",
    "pd.options.display.max_colwidth = 50\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DyNLhFSVxRlW",
   "metadata": {
    "id": "DyNLhFSVxRlW"
   },
   "outputs": [],
   "source": [
    "def plot_metric(history, metric='loss'):\n",
    "    \"\"\" Plot training and test values for a metric. \"\"\"\n",
    "\n",
    "    val_metric = 'val_'+metric\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history[val_metric])\n",
    "    plt.title('model '+metric)\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'])\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UZoJCxr2AT6Q",
   "metadata": {
    "id": "UZoJCxr2AT6Q"
   },
   "source": [
    "This will help with replicability, but does not control all aspects of randomness in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6XQbXT1gAQol",
   "metadata": {
    "id": "6XQbXT1gAQol"
   },
   "outputs": [],
   "source": [
    "np.random.seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CKd5eMtxw3QO",
   "metadata": {
    "id": "CKd5eMtxw3QO"
   },
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xp4u-WKrpNN-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9496,
     "status": "ok",
     "timestamp": 1665681569869,
     "user": {
      "displayName": "Glenn",
      "userId": "10553525024667050874"
     },
     "user_tz": 420
    },
    "id": "xp4u-WKrpNN-",
    "outputId": "8d9ac97a-b9c7-46fa-f1bb-c0a89caa1762"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 6s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RQ7kVtboXqpk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 252,
     "status": "ok",
     "timestamp": 1665681572876,
     "user": {
      "displayName": "Glenn",
      "userId": "10553525024667050874"
     },
     "user_tz": 420
    },
    "id": "RQ7kVtboXqpk",
    "outputId": "3714db47-82ce-42fb-d8df-ba5d5de65a58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VAIQYRHJor41",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1665681576392,
     "user": {
      "displayName": "Glenn",
      "userId": "10553525024667050874"
     },
     "user_tz": 420
    },
    "id": "VAIQYRHJor41",
    "outputId": "fcf551cc-6ecb-4690-c176-b78be36eec90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 255\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.min(), X_train.max())\n",
    "print(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vOSxuz2SGsPW",
   "metadata": {
    "id": "vOSxuz2SGsPW"
   },
   "source": [
    "#### We'll use a smaller version of the data to speed up the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QNv46FKtGXBJ",
   "metadata": {
    "id": "QNv46FKtGXBJ"
   },
   "outputs": [],
   "source": [
    "idx = np.random.choice(X_train.shape[0], 25000, replace=False)\n",
    "X_train = X_train[idx]\n",
    "y_train = y_train[idx]\n",
    "\n",
    "idx = np.random.choice(X_test.shape[0], 8000, replace=False)\n",
    "X_test = X_test[idx]\n",
    "y_test = y_test[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KblcmCnEw64O",
   "metadata": {
    "id": "KblcmCnEw64O"
   },
   "source": [
    "### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aDkzEKMbqEzX",
   "metadata": {
    "id": "aDkzEKMbqEzX"
   },
   "outputs": [],
   "source": [
    "# from integers in [0,255] to float in [0,1]\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test  = X_test.astype('float32') / 255\n",
    "\n",
    "# store the labels in 1D arrays, not 2D\n",
    "y_train = np.squeeze(y_train)  # this could also be done using reshape\n",
    "y_test = np.squeeze(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qDQl-cEyrBF-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1665681585784,
     "user": {
      "displayName": "Glenn",
      "userId": "10553525024667050874"
     },
     "user_tz": 420
    },
    "id": "qDQl-cEyrBF-",
    "outputId": "5e0b914e-e8be-4631-c564-4cb1fd45a676"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 32, 32, 3)\n",
      "(25000,)\n",
      "(8000, 32, 32, 3)\n",
      "(8000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mUaP48QMxAr-",
   "metadata": {
    "id": "mUaP48QMxAr-"
   },
   "source": [
    "### Create the baseline CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6R19-j3KH465",
   "metadata": {
    "id": "6R19-j3KH465"
   },
   "source": [
    "#### Problem 1: fill in the input shape value below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YLyUejIoYDY8",
   "metadata": {
    "id": "YLyUejIoYDY8"
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=None))  # replace None with your code\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# output layer\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "t6K5yInu7vrd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1634941620309,
     "user": {
      "displayName": "Glenn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjykiG4UrEIFJrppAQQSHHr3TjS4DL1ZBM99aAAdg=s64",
      "userId": "10553525024667050874"
     },
     "user_tz": 420
    },
    "id": "t6K5yInu7vrd",
    "outputId": "8b1fc3c2-aadd-48e9-c6d5-46c3874d1e80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 167,562\n",
      "Trainable params: 167,562\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FpoOKUmuxJW-",
   "metadata": {
    "id": "FpoOKUmuxJW-"
   },
   "source": [
    "### Compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "T_IIeKIprTd9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T_IIeKIprTd9",
    "outputId": "e0b1f480-9211-4bf5-dbfd-cc2b087febae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "391/391 [==============================] - 32s 79ms/step - loss: 1.7775 - accuracy: 0.3615 - val_loss: 1.4942 - val_accuracy: 0.4787\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 31s 78ms/step - loss: 1.4199 - accuracy: 0.5009 - val_loss: 1.3729 - val_accuracy: 0.5134\n",
      "Epoch 3/5\n",
      "268/391 [===================>..........] - ETA: 8s - loss: 1.2665 - accuracy: 0.5592"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nlH1i7gvrXx9",
   "metadata": {
    "id": "nlH1i7gvrXx9"
   },
   "outputs": [],
   "source": [
    "plot_metric(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UhDBNNZv7DUf",
   "metadata": {
    "id": "UhDBNNZv7DUf"
   },
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "N1aL1Fjq7F-_",
   "metadata": {
    "id": "N1aL1Fjq7F-_"
   },
   "source": [
    "In each experiment, compare an alternative model to the baseline model.\n",
    "\n",
    "The amount of training that is needed will depend on the model.  You can adjust the number of epochs and you can use Use early stopping if you like.\n",
    "\n",
    "**After each experiment, think about and comment on**:\n",
    "- the size of the model (in terms of number of parameters)\n",
    "- how long the model takes to train\n",
    "- the validation accuracy you can achieve\n",
    "- the amount of overfitting\n",
    "\n",
    "Avoid making vague statements like: \"this model performs a little better than the baseline\", or\n",
    "\"we see a little overfitting\".  Try to be quantitative.  What are you using to compare\n",
    "your model to the baseline: validation accuracy, validation loss, or ...?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cboxDdduxsc2",
   "metadata": {
    "id": "cboxDdduxsc2"
   },
   "source": [
    "### Experiment: Stack two convolutional layers\n",
    "\n",
    "It is pretty common in CNN models to \"stack\" convolutional layers.  This means using two or more convolutional layers without pooling layers between them.\n",
    "\n",
    "Create a model like the baseline, but add a second convolutional layer after the first convolutional layer.  You can use a layer with the same number of output channels and same filter size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vHCiHqK9Y_YM",
   "metadata": {
    "id": "vHCiHqK9Y_YM"
   },
   "source": [
    "#### Problem 2: Copy the your baseline model and modify it to add the convolutional layer.  You may modify the fit() call to control the number of epochs.  Also, add your comments in the markdown cell after the plot_metric() cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jvVqEYTpxVm2",
   "metadata": {
    "id": "jvVqEYTpxVm2"
   },
   "outputs": [],
   "source": [
    "# YOUR MODEL HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EvZ-uZZO8MAo",
   "metadata": {
    "id": "EvZ-uZZO8MAo"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xOtI8idr6dwo",
   "metadata": {
    "id": "xOtI8idr6dwo"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MaqBRiUu6g0U",
   "metadata": {
    "id": "MaqBRiUu6g0U"
   },
   "outputs": [],
   "source": [
    "plot_metric(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ciUSzWtZV2_",
   "metadata": {
    "id": "6ciUSzWtZV2_"
   },
   "source": [
    "(YOUR COMMENTS HERE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VaUmuhcT6_BP",
   "metadata": {
    "id": "VaUmuhcT6_BP"
   },
   "source": [
    "### Experiment: Stack both convolutional layers\n",
    "\n",
    "#### Problem 3.  Create a model like the baseline, but with each of the original convolutional layers replaced by a pair of convolutional layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kBu2WBnLJmPB",
   "metadata": {
    "id": "kBu2WBnLJmPB"
   },
   "source": [
    "#### YOUR CELLS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "L9ra43h-AmI4",
   "metadata": {
    "id": "L9ra43h-AmI4"
   },
   "source": [
    "### Experiment: Remove the next-to-last dense layer\n",
    "\n",
    "#### Problem 4.  Create a model like the baseline, but remove the dense layer before the final layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qQMxmdJtDaqQ",
   "metadata": {
    "id": "qQMxmdJtDaqQ"
   },
   "source": [
    "#### YOUR CELLS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZuZ5XWc2CSRD",
   "metadata": {
    "id": "ZuZ5XWc2CSRD"
   },
   "source": [
    "### Experiment: Modify the convolutional kernel size.\n",
    "\n",
    "#### Problem 5. The baseline has 3x3 kernels.  Make a modified version of the baseline using a different size.  However, use the same kernel size in both convolutional layersl.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0h6HghfDffA",
   "metadata": {
    "id": "a0h6HghfDffA"
   },
   "source": [
    "#### YOUR CELLS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4BauOmhAnUn",
   "metadata": {
    "id": "a4BauOmhAnUn"
   },
   "source": [
    "### Experiment: Replace ReLU activation functions with elu\n",
    "\n",
    "#### Problem 6.  Create a model like the baseline, but with the ReLU activiation functions replaced by ELU activation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PeCYSTWIDheL",
   "metadata": {
    "id": "PeCYSTWIDheL"
   },
   "source": [
    "#### YOUR CELLS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5rnYAQQWAosQ",
   "metadata": {
    "id": "5rnYAQQWAosQ"
   },
   "source": [
    "### Experiment: Replace the rmsprop optimizer with adam\n",
    "\n",
    "#### Problem 7.  Create a model like the baseline, but use the adam optimizer instead of rmsprop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Yk6t1hq4Djtw",
   "metadata": {
    "id": "Yk6t1hq4Djtw"
   },
   "source": [
    "#### YOUR CELLS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7Tq5izFVBHuw",
   "metadata": {
    "id": "7Tq5izFVBHuw"
   },
   "source": [
    "### Challenge: Create the best small model you can\n",
    "\n",
    "#### Problem 8.  Create a CNN model, using only Conv2D(), MaxPooling2D(), Flatten(), and Dense(), with the best possible validation accuracy.\n",
    "\n",
    "Your model must have less than 60,000 parameters.\n",
    "\n",
    "Do not try ingredients outside the scope of this assignment, like pre-defined models.  The idea is for you to get a good feeling for basic CNNs at this time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XRDmKF6HDmNg",
   "metadata": {
    "id": "XRDmKF6HDmNg"
   },
   "source": [
    "#### YOUR CELLS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Kfam5PH7B3gw",
   "metadata": {
    "id": "Kfam5PH7B3gw"
   },
   "source": [
    "### Challenge Create the best model you can\n",
    "\n",
    "#### Problem 9: Create a CNN model, using  Conv2D(), MaxPooling2D(), Flatten(), and Dense(), with the best possible validation accuracy.\n",
    "\n",
    "You can also use dropout, batch normalization, and weight regularization.  You can modify the optimizer, the optimizer parameters, and weight regularization.\n",
    "\n",
    "Note that, in CNNs, when dropout is used it is often applied after pooling.\n",
    "\n",
    "**Only use ingredients covered in class**.  For example, don't use pre-defined models.  The one exception: you can use SpatialDropout, which is a form of dropout suited to CNNs.\n",
    "\n",
    "Your model can have as many parameters as you like.  You can modify the optimizer, the optimizer parameters, and the activation function.  Also, you can try dropout, batch normalization, and weight regularization.\n",
    "\n",
    "Remember to start with a model that overfits, and then control overfitting.\n",
    "\n",
    "You are encouraged to use the grad search and/or random search code of last week's assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xZSH449KDogY",
   "metadata": {
    "id": "xZSH449KDogY"
   },
   "source": [
    "#### YOUR CELLS HERE"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
