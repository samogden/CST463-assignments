{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vkjvb11s5EJu"
   },
   "source": [
    "# Activity recognition with accelerometer data using a convolutional neural network\n",
    "\n",
    "(Assignment developed by Dr. Bruns)\n",
    "\n",
    "In this notebook we build an activity recognizer using a 1D-convolutional network.  There are seven different activities, so this is a multi-class classifier.\n",
    "\n",
    "A question that comes up in activity recognition is:\n",
    "- Is it possible to build a generic activity recognizer that does not need to be special tuned on data from the user that will use it?\n",
    "\n",
    "In this notebook we'll do experiments to see if a custom activity recognizer (trained for its user) would be much more accurate than a generic one.\n",
    "\n",
    "v1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVPAb0JJbSiO"
   },
   "source": [
    "## Instructions:\n",
    "- There are 7 clearly-identified problems below.\n",
    "- Work on your own.  Do not look on the web for ideas on activity recognition.\n",
    "- In all problems except problem 1, you are free to create multiple markdown and code cells, to create plots, to define new functions, etc.\n",
    "- Provide commentary on the results of every problem.\n",
    "- Feel free to use the hyperparameter tuning functions that were defined in a previous homework.\n",
    "- Be sure to clearly report on accuracy values when you are asked to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m7ZSPy8U4_UT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import find_peaks, periodogram\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EDwHVC0TbAo2"
   },
   "outputs": [],
   "source": [
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9hMerEObR1AR"
   },
   "source": [
    "Names associated with the activity numbers in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBN3sFXH4_Ub"
   },
   "outputs": [],
   "source": [
    "activity_names = ['desk', 'mixed', 'standing', 'walking', 'stairs', 'talking/walking', 'talking/standing']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PVKYbQhR1AS"
   },
   "source": [
    "Functions to help with reading and preprocessing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uqCooPHER1AT"
   },
   "outputs": [],
   "source": [
    "def read_user_data(user_id):\n",
    "    \"\"\" Return a data frame containing the data for the given user.\n",
    "    Args:\n",
    "        user_id an integer user id from 1 to 15.\n",
    "    \"\"\"\n",
    "\n",
    "    infile = f'https://raw.githubusercontent.com/grbruns/cst495/master/activity/{user_id}.csv'\n",
    "    df = pd.read_csv(infile, index_col=0, header=None)\n",
    "\n",
    "    df.columns = ['x', 'y', 'z', 'activity']\n",
    "    df = df[df['activity'] != 0]\n",
    "    df['activity'] = df['activity'] - 1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MedQAGQj4_UY"
   },
   "outputs": [],
   "source": [
    "def create_segments(X, window_size, shift):\n",
    "    \"\"\" Return a list of NumPy arrays, each a segment.\n",
    "\n",
    "    X is a numpy array with shape (number of time steps, number of variables)\n",
    "    window_size defines the size of the segments\n",
    "    shift is the number of time steps to shift the window\n",
    "\n",
    "    The output is a NumPy array with shape (k, window_size, n)\n",
    "    \"\"\"\n",
    "\n",
    "    # compute number of segments in X\n",
    "    # X.shape[0]/shift gives total number of window positions\n",
    "    num_segments = np.floor(X.shape[0]/shift) - np.ceil(window_size/shift)\n",
    "    num_segments = int(num_segments)\n",
    "\n",
    "    # create the segments\n",
    "    segments = np.zeros((num_segments, window_size, X.shape[1]))\n",
    "    for i in np.arange(num_segments):\n",
    "        segments[i, :, :] = X[(i*shift):(i*shift + window_size), :]\n",
    "\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y67_U1LU4_Ul"
   },
   "outputs": [],
   "source": [
    "def clean_and_label(segments):\n",
    "    \"\"\" From the given segments, create a new array of the clean segments.\n",
    "    Return the clean segments, with activity values removed,\n",
    "    and an activity label for each.\n",
    "    \"\"\"\n",
    "\n",
    "    # compute number of single class (\"clean\") segments\n",
    "    n = segments.shape[0]\n",
    "    num_clean = 0\n",
    "    for i in range(n):\n",
    "        segment_classes = segments[i,:,3]\n",
    "        if segment_classes.min() == segment_classes.max():\n",
    "            num_clean += 1\n",
    "\n",
    "    print('fraction of segments with a single class: {:.3f}'.format(num_clean/n))\n",
    "\n",
    "    # create clean segments, and create training labels\n",
    "    segs = np.zeros((num_clean, segments.shape[1], segments.shape[2]-1))\n",
    "    y = np.full(num_clean, 0)\n",
    "    idx = 0\n",
    "    for i in range(n):\n",
    "        segment_classes = segments[i,:,3]\n",
    "        if segment_classes.min() == segment_classes.max():\n",
    "            segs[idx,:,:] = segments[i,:,:3]\n",
    "            y[idx] = segment_classes[0]\n",
    "            idx += 1\n",
    "\n",
    "    return segs, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCW_AQ9lR1AV"
   },
   "source": [
    "A function to help with diagnosis of neural net training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "shZkiChU2ik-"
   },
   "outputs": [],
   "source": [
    "def plot_metric(history, metric='loss'):\n",
    "    \"\"\" Plot training and test values for a metric. \"\"\"\n",
    "\n",
    "    val_metric = 'val_'+metric\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history[val_metric])\n",
    "    plt.title('model '+metric)\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'])\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4IpHuhOx4_UZ"
   },
   "source": [
    "### Read the raw data\n",
    "\n",
    "The data set comes from the UCI repository:\n",
    "\n",
    "[Activity Recognition from Single Chest-Mounted Accelerometer Data Set](https://archive.ics.uci.edu/ml/datasets/Activity+Recognition+from+Single+Chest-Mounted+Accelerometer)\n",
    "\n",
    "The data was apparently collected at the University of Barcelona in about 2009.\n",
    "\n",
    "The data set contains data for 15 people.  During data collection, each person wore a chest-mounted accelerometer, and x/y/z data was collected at 52 Hz (52 samples/second)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J3e_lWo_R1AW"
   },
   "outputs": [],
   "source": [
    "# Load data for a single user.  Users are numbered 1-15.\n",
    "\n",
    "df = read_user_data(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_os9SVM4_Uc"
   },
   "source": [
    "### Initial exploration\n",
    "\n",
    "The three columns of the data contain samples in the x, y, and z dimensions.  There are about 120K samples for each of x, y, and z, so, based on the sample rate, about 2300 seconds (38 minutes) of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X3bzIZ5A4_Ud"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L_oMHgFu4_Uf"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wSBwguNp4_Ug"
   },
   "outputs": [],
   "source": [
    "df['activity'].value_counts().plot.bar()\n",
    "plt.title('Counts of activities');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q9_LM-fh4_Uh"
   },
   "source": [
    "### Data segmentation and cleaning\n",
    "\n",
    "As a first step we need to break the data up into segments and assign a label to each segment.  \n",
    "\n",
    "The process of labeling is a little tricky, because not every segment has a single label associated with it.\n",
    "\n",
    "Remember that the data was sampled at 52 Hz.  In other words, a segment of length 52 would contain 1 second of recorded activity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eh-UmBATR1AX"
   },
   "source": [
    "---\n",
    "#### Problem 1: set the data segmentation parameters\n",
    "\n",
    "In this problem, set the window_size and shift values.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Dnvmlrx4_Uj"
   },
   "outputs": [],
   "source": [
    "window_size = None      # select a segment size\n",
    "shift = None            # select a shift amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fFYUD2eSR1AX"
   },
   "outputs": [],
   "source": [
    "df = read_user_data(4)\n",
    "segments = create_segments(df.values, window_size, shift)\n",
    "X, y = clean_and_label(segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OyfWck6OW2fy"
   },
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6gdtn45WzLc"
   },
   "source": [
    "### Prepare data for machine learning\n",
    "\n",
    "Perform any further preprocessing, then do a train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qs2mJx0mVy1l"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CqwAR2DMXorl"
   },
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9BN9AAoX4_Um"
   },
   "source": [
    "Plot a random clean segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zDfKpT8A4_Um"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "i = np.random.choice(X_train.shape[0])\n",
    "plt.plot(X_train[i])\n",
    "plt.title(activity_names[y_train[i]]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSOfKf1bR1AZ"
   },
   "source": [
    "---\n",
    "#### Problem 2: Perform any additional preprocessing of the data that you want.\n",
    "---\n",
    "\n",
    "This problem is optional; you may choose to not perform any additional preprocessing.\n",
    "\n",
    "Remember to treat training and test data correctly.  For example, if you do any scaling or normalization, train the scaler on the training data and then apply it on the test data.  As another example, if you do any balancing of the data, do the balancing only on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-MEySID6R1AZ"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE AND MARKDOWN CELLS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AlmRdKFi4_Up"
   },
   "source": [
    "### Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yM1Rm5Mp4_Up"
   },
   "source": [
    "The goal is to predict the activity of a training example.  This is a multi-class classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n14qG63e4_Up"
   },
   "outputs": [],
   "source": [
    "# to get baseline accuracy, always predict the most common activity\n",
    "counts = df['activity'].value_counts()/df.shape[0]\n",
    "print('baseline accuracy: {:0.4f}'.format(counts[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZQPp521a1y1"
   },
   "source": [
    "This is to help ensure that a standard data set is being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IgDSWJC4atFK"
   },
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_train.sum(), X_test.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPqvqA_lYOuu"
   },
   "source": [
    "---\n",
    "#### Problem 3:  Create a 1D convolutional net to predict the activity from a segment.  \n",
    "---\n",
    "\n",
    "The accelerometer data has three channels (for the x, y, and z axes of movement).  These will be the input channels of the model.\n",
    "\n",
    "Be sure to report on the test accuracy of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OLPgLIPnTFRs"
   },
   "outputs": [],
   "source": [
    "# delete any old models\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ufSPFyASR1Aa"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE AND MARKDOWN CELLS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ix2A1wUoR1Aa"
   },
   "source": [
    "---\n",
    "#### Problem 4: Compute the accuracy of your model on data from users 1, 2, and 3.\n",
    "---\n",
    "\n",
    "Does the model you trained on data from user 4 make good predictions on data from other people?  \n",
    "\n",
    "Compute the accuracy of your model on 1.csv, on 2.csv, and on 3.csv.\n",
    "\n",
    "Do not train the model in this step; just compute the accuracy of the model that you trained in the previous problem.\n",
    "\n",
    "Make sure you clearly print three accuracy values: the accuracy on 1.csv, on 2.csv, and on 3.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j0Spah_eR1Aa"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE AND MARKDOWN CELLS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PjFQvbMiR1Aa"
   },
   "source": [
    "---\n",
    "#### Problem 5: Train and then compute the accuracy of your model on data from users 1, 2, and 3.\n",
    "---\n",
    "\n",
    "Does the model you tuned for user 4 work make good predictions for user 1, when trained on data from user 1?\n",
    "\n",
    "Split the user 1 data into a training and test sets, do the same preprocessing you did for data from user 4, train the model, and then compute test accuracy.\n",
    "\n",
    "Repeat the process for users 2 and 3.\n",
    "\n",
    "Remember, you will not modify your model of problem 3, but you will train it and compute accuracy for each of users 1-3.\n",
    "\n",
    "Hint: re-read these instructions carefully!  You will need to train and test separately for each of users 1, 2, and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mO6ova_kR1Aa"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE AND MARKDOWN CELLS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1c4OfGTR1Aa"
   },
   "source": [
    "---\n",
    "#### Problem 6: Create a new model, train it on users 1-11, and test it on users 12-15.\n",
    "---\n",
    "\n",
    "Can you make a generic model that will work well for everybody?\n",
    "\n",
    "Create a new model, then fit it using data from users 1-11 as your training data.  You will have to combine the data from these people into a single training data set.\n",
    "\n",
    "Then compute the accuracy of your model, individually, on users 12-15.\n",
    "\n",
    "Combining data from users 1-11 into a single dataset is easy to do with Pandas dataframes using the concat() function.  For example, `df = pd.concat([df1, df2])`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62AJ08crR1Ab"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE AND MARKDOWN CELLS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OVbXmy2nR1Ab"
   },
   "source": [
    "---\n",
    "#### Problem 7: Write your final conclusions.  Write clearly, and write in paragraphs.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ERslcsqdR1Ab"
   },
   "source": [
    "(Replace this with your text.)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
