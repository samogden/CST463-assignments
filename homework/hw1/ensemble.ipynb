{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adbda950",
   "metadata": {
    "id": "adbda950"
   },
   "source": [
    "# Random forests for house price prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23de51b3",
   "metadata": {
    "id": "23de51b3"
   },
   "source": [
    "Your Name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513adc6d",
   "metadata": {
    "id": "513adc6d"
   },
   "source": [
    "The purpose of this assignment is to give you experience with ensemble methods while answering a couple of questions:\n",
    "- How do random forests perform, compared to single trees?\n",
    "- What are the hyperparameters of random forests?  Does tuning take a long time?\n",
    "- What does the concept of \"feature importance\" in random forests mean? \n",
    "\n",
    "We'll examine these questions using the CA Housing dataset.  You can get information about the dataset here: https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset.\n",
    "\n",
    "You will probably want to look at that web page to understand the variables in the dataset.\n",
    "\n",
    "There are three problems to solve.\n",
    "\n",
    "__Instructions__:\n",
    "- Read this notebook to get a feeling for its structure.  Don't modify the top-level structure.\n",
    "- Don't modify the cell that loads the data.\n",
    "- Write code to answer the 3 problems.  Look for # YOUR CODE HERE comments.  You also need to write a summary at the end of each problem.\n",
    "- Please make sure to read the grading rubric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4829a575",
   "metadata": {
    "id": "4829a575"
   },
   "outputs": [],
   "source": [
    "# add more imports as needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fffccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.set_context('talk')\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b473385b",
   "metadata": {
    "id": "b473385b"
   },
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf6a8d0",
   "metadata": {
    "id": "3cf6a8d0"
   },
   "source": [
    "From 8 numeric predictors we will try to predict the house value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f22222",
   "metadata": {
    "id": "f7f22222"
   },
   "outputs": [],
   "source": [
    "# df is a data frame of the predictors; target is a Series with the target\n",
    "bunch = fetch_california_housing(as_frame=True)\n",
    "df = bunch.data\n",
    "target = bunch.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc39a84f",
   "metadata": {
    "id": "dc39a84f"
   },
   "source": [
    "## Data exploration\n",
    "\n",
    "You can add more data exploration if you like, but it's not needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab35c59",
   "metadata": {
    "id": "eab35c59",
    "outputId": "a2c85661-9df0-4261-ffb5-2d8d2a781791"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278296ff",
   "metadata": {
    "id": "278296ff",
    "outputId": "1b62e481-1f34-4059-e45c-9117fa8f4c08"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4770276b",
   "metadata": {
    "id": "4770276b",
    "outputId": "42d14512-9d37-44a1-e4d0-bdf75ffd9fc8",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "target.plot.hist()\n",
    "plt.title('Histogram of house values');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4c6d6d",
   "metadata": {
    "id": "1375651b"
   },
   "source": [
    "#### Check for outlier values of predictor variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd954d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize to make it easier to see outliers\n",
    "dfs = df.apply(zscore)\n",
    "\n",
    "# https://stackoverflow.com/questions/41328633 explains formatting\n",
    "with pd.option_context('float_format', '{:.2f}'.format): \n",
    "    print(dfs.describe(percentiles=[0.5, 0.95, 0.99])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad46e7f7",
   "metadata": {},
   "source": [
    "The result of describe on the z-score normalized values show some extreme outliers in variables AveRooms, AveBedrms, Population, and AveOccup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0dfa61",
   "metadata": {
    "id": "eb0dfa61"
   },
   "source": [
    "## Data preprocessing\n",
    "\n",
    "In this section we first remove the outliers found earlier, then perform a test/train split and scale the data.\n",
    "\n",
    "Also, a smaller version of the dataset is created to speed up hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6657c2e4",
   "metadata": {},
   "source": [
    "#### Remove outliers in columns that have significant outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7619f9b5",
   "metadata": {
    "id": "7619f9b5"
   },
   "outputs": [],
   "source": [
    "high_vals = df.quantile(0.99)\n",
    "for col in ['AveRooms', 'AveBedrms', 'Population', 'AveOccup']:\n",
    "    mask = df[col] <= high_vals[col]\n",
    "    df = df[mask]\n",
    "    target = target[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b5a508",
   "metadata": {},
   "source": [
    "#### How many rows after outlier removal? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42956c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of rows in data frame: {df.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66339509",
   "metadata": {},
   "source": [
    "#### Transform the data to NumPy arrays, perform a train/test split, and then scale the data.\n",
    "\n",
    "The test data is not used in fitting the scaler -- that would \"leak\" information about the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f9035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.values\n",
    "y = target.values\n",
    "\n",
    "# 20% should be enough for the test set, as the data set has 20K rows\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0f38ef",
   "metadata": {},
   "source": [
    "#### Make a smaller version of the training data to allow for faster hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35c2b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 50% of the data in the sample\n",
    "np.random.seed(0)\n",
    "m = X_train.shape[0]\n",
    "rows = np.random.choice(m, size=int(m*0.5), replace=False)\n",
    "X_train_s = X_train[rows]\n",
    "y_train_s = y_train[rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dde8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_s.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb88d861",
   "metadata": {},
   "source": [
    "## Problem 1. Regression with a single regression tree\n",
    "\n",
    "In this problem you will tune a regression tree using GridSearchCV, then look at the importance of the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9445b9c0",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63007570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GridSearchCV to tune a DecisionTreeRegressor.  \n",
    "# You will need to create a dictionary, which is often given variable name 'param_grid'.\n",
    "# Only tune the DecisionTreeRegressor hyperparameters 'max_leaf_nodes' and 'max_depth'.  \n",
    "# Be sure to include large enough possible values\n",
    "\n",
    "# Hint: create a GridSearchCV object and then use the .fit() method.\n",
    "# Hint: don't forget to specify the scoring parameter when you use GridSearchCV.\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d82a4c2",
   "metadata": {},
   "source": [
    "### Report on the best parameters and the score associated with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de84c69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best hyperparameter values and the best CV RMSE value.\n",
    "# Use two print statements.\n",
    "# Hint: you can get the values you want from your trained GridSearchCV object.\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81351d2",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01ba26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a horizontal bar plot showing the feature importance for each predictor variable.\n",
    "# Give the plot an appropriate title and x/y axis labels.\n",
    "\n",
    "# Hint: you can get the feature importances from your GridSearchCV object by\n",
    "# first accessing the best estimator that the GridSearchCV found.\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3488b2ad",
   "metadata": {
    "id": "421e327e"
   },
   "source": [
    "### Summary\n",
    "\n",
    "Replace this text with your own discussion about what you learned on this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9685bff",
   "metadata": {
    "id": "f9685bff"
   },
   "source": [
    "## Problem 2. Regression with a random forest\n",
    "\n",
    "For this problem you tune a random forest and see how well it performs.  Does it outperform a single tree?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d337252a",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning\n",
    "\n",
    "Note that a `max_features` value of 1 means \"bagged trees\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf89fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform GridSearchCV again, but this time with a RandomForestRegressor.\n",
    "# Your param_grid should contain values for only max_depth and max_features.\n",
    "# For max_depth, I recommend you look at some small integer values, plus value None.\n",
    "# For max_features, I recommend you look at values 1.0 and 'sqrt'.\n",
    "# Read the RandomForestRegressor to understand what these hyperparameter values mean.\n",
    "\n",
    "# Hint: don't consider too many values in your param grid, because this can take a while to run.\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969c9977",
   "metadata": {},
   "source": [
    "### Report on the best parameters and the score associated with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcecf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce output similar to what you did for a single regression tree.\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a63af1c",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9d0408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestRegressor also supports the concept of feature importance.\n",
    "# Print a horizontal bar plot like you did for your single regression tree.\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421e327e",
   "metadata": {
    "id": "421e327e"
   },
   "source": [
    "### Summary\n",
    "\n",
    "Replace this text with your own discussion about what you learned on this problem.  Be sure to compare your results for random forests with your results for a single regression tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad24b12",
   "metadata": {
    "id": "dad24b12"
   },
   "source": [
    "## Problem 3. Tuning the number of base regressors\n",
    "\n",
    "Now we find the best number of best regressors, keeping the hyperparameter values in the last part unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a52b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a param_grid dictionary based on the best hyperparameter you found in the last problem.\n",
    "# The dictionary should have a list containing only one value for those hyperparameters,\n",
    "# but should additionally have a 'n_estimators' key that has as its value a list with multiple elements.\n",
    "\n",
    "# Hint: to create a param_grid from a dictionary of best hyperparameter values, you can\n",
    "# use a dictionary comprehension, like this:\n",
    "# param_grid = {k: [v] for k, v in best_hyper_vals.items()}\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305445f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leave this cell alone\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a81ca1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform a grid search again.  Now the only parameter being tuned is n_estimators.\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c030c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As before, print the best hyperparameter values and the best CV RMSE.\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e1c241",
   "metadata": {},
   "source": [
    "#### Examine how score varies by the number of estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc26aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar plot showing RMSE (y axis) by number of tree (x axis)\n",
    "\n",
    "# Hint: I found it useful to use pd.DataFrame() on the cross validation results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78f1a13",
   "metadata": {
    "id": "b78f1a13"
   },
   "source": [
    "### Summary\n",
    "\n",
    "Replace this text with your own comments on what you learned in this problem."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ensemble.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
