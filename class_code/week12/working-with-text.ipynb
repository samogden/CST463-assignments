{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-13T17:09:03.592153Z",
     "start_time": "2024-11-13T17:09:00.610522Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T17:09:03.595422Z",
     "start_time": "2024-11-13T17:09:03.592346Z"
    }
   },
   "id": "e82818291c958b77"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# tf.data input"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c3420fe394fc340"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "text_dataset = tf.data.Dataset.from_tensor_slices([\"You gotta do it till you're through it\"])\n",
    "vectorize_layer = keras.layers.TextVectorization(\n",
    "  output_mode='int',\n",
    "  max_tokens=5,                # limit the number of tokens\n",
    "  output_sequence_length=4     # limit output sequence length\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T17:09:34.158619Z",
     "start_time": "2024-11-13T17:09:34.145783Z"
    }
   },
   "id": "d9395f27085cc6a8"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', 'it', 'youre', 'you']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vectorize_layer.adapt(text_dataset)\n",
    "print(vectorize_layer.get_vocabulary())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T17:09:42.463120Z",
     "start_time": "2024-11-13T17:09:42.432533Z"
    }
   },
   "id": "8fe7494cb7f2677b"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([4 1 1 2], shape=(4,), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 09:09:43.793338: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text_vectorized = text_dataset.map(vectorize_layer)\n",
    "for text in text_vectorized:\n",
    "  print(text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T17:09:43.798178Z",
     "start_time": "2024-11-13T17:09:43.713552Z"
    }
   },
   "id": "d08e20e47609ee3d"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T17:09:49.102191Z",
     "start_time": "2024-11-13T17:09:49.086275Z"
    }
   },
   "id": "1132c6f5bb796ac8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Out-of-vocab words"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "194c155500ada209"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2 1 3 0], shape=(4,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "text_dataset = tf.data.Dataset.from_tensor_slices([\"foo bar\", \"foo foo bar baz\"])\n",
    "# bif does not appear in text_dataset\n",
    "new_dataset = tf.data.Dataset.from_tensor_slices([\"foo bif bar\"])\n",
    "\n",
    "vectorize_layer = keras.layers.TextVectorization(\n",
    "  output_mode='int',\n",
    "  max_tokens=5,\n",
    "  output_sequence_length=4\n",
    ")\n",
    "\n",
    "vectorize_layer.adapt(text_dataset)\n",
    "\n",
    "text_vectorized = new_dataset.map(vectorize_layer)\n",
    "for text in text_vectorized:\n",
    "  print(text)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T17:18:06.921488Z",
     "start_time": "2024-11-13T17:18:06.792783Z"
    }
   },
   "id": "962cd88608039ec5"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 1 0 0], shape=(4,), dtype=int64)\n",
      "tf.Tensor([1 3 1 0], shape=(4,), dtype=int64)\n",
      "tf.Tensor([1 1 1 1], shape=(4,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "new_dataset = tf.data.Dataset.from_tensor_slices([\"bif bif\", \"bif bar bif\", \"bif bif bif bif bif bar\"])\n",
    "\n",
    "text_vectorized = new_dataset.map(vectorize_layer)\n",
    "for text in text_vectorized:\n",
    "  print(text)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T17:18:07.551751Z",
     "start_time": "2024-11-13T17:18:07.466520Z"
    }
   },
   "id": "c509d81c3510f1e3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# mutli-hot encoding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6735cc0579cff792"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 0 1], shape=(4,), dtype=int64)\n",
      "tf.Tensor([0 0 1 1], shape=(4,), dtype=int64)\n",
      "tf.Tensor([0 1 1 0], shape=(4,), dtype=int64)\n",
      "tf.Tensor([0 1 1 1], shape=(4,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "text_dataset = tf.data.Dataset.from_tensor_slices([\"foo bar\", \"bar baz\", \"baz foo\", \"foo foo bar baz\"])\n",
    "vectorize_layer = keras.layers.TextVectorization(\n",
    "  output_mode='multi_hot',   # aka binary encoding\n",
    "  max_tokens=5\n",
    ")\n",
    "\n",
    "vectorize_layer.adapt(text_dataset)\n",
    "# Vectorize the text -- note the 0 outputs\n",
    "text_mh = text_dataset.map(vectorize_layer)\n",
    "for text in text_mh:\n",
    "  print(text)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T17:19:01.348079Z",
     "start_time": "2024-11-13T17:19:01.260444Z"
    }
   },
   "id": "9db5c46ebad47884"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 0 0 0], shape=(4,), dtype=int64)\n",
      "tf.Tensor([1 0 0 1], shape=(4,), dtype=int64)\n",
      "tf.Tensor([1 0 0 1], shape=(4,), dtype=int64)\n",
      "tf.Tensor([0 1 0 1], shape=(4,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "new_dataset = tf.data.Dataset.from_tensor_slices([\n",
    "  \"bif bif\", \n",
    "  \"bif bar bif\", \n",
    "  \"bif bif bif bif bif bar\",\n",
    "  \"foo bar\"\n",
    "])\n",
    "\n",
    "text_vectorized = new_dataset.map(vectorize_layer)\n",
    "for text in text_vectorized:\n",
    "  print(text)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T17:19:48.603317Z",
     "start_time": "2024-11-13T17:19:48.500877Z"
    }
   },
   "id": "e1b855f07f786310"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "327b95f316629186"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# tf-idf\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50132e25dcd7c240"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T17:21:14.527219Z",
     "start_time": "2024-11-13T17:21:14.498522Z"
    }
   },
   "id": "670235da7d31c19e"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T17:21:14.713790Z",
     "start_time": "2024-11-13T17:21:14.689849Z"
    }
   },
   "id": "94c0a01de7f67edf"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T17:21:14.876591Z",
     "start_time": "2024-11-13T17:21:14.857293Z"
    }
   },
   "id": "498744258122affd"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T17:21:15.059802Z",
     "start_time": "2024-11-13T17:21:15.042253Z"
    }
   },
   "id": "653580f93f43466a"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T17:21:15.187381Z",
     "start_time": "2024-11-13T17:21:15.172950Z"
    }
   },
   "id": "b399cae2ec501fa4"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T17:21:15.368973Z",
     "start_time": "2024-11-13T17:21:15.347933Z"
    }
   },
   "id": "dedef6b8bc0a4dea"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.        0.6931472 0.        0.6931472], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0.        0.        0.6931472 0.6931472], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0.        0.6931472 0.6931472 0.       ], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0.        1.3862944 0.6931472 0.6931472], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "text_dataset = tf.data.Dataset.from_tensor_slices([\"foo bar\", \"bar baz\", \"baz foo\", \"foo foo bar baz\"])\n",
    "vectorize_layer = keras.layers.TextVectorization(\n",
    "  output_mode='tf-idf',   # term freq. â€“ inverse document freq.\n",
    "  max_tokens=5\n",
    ")\n",
    "\n",
    "vectorize_layer.adapt(text_dataset)\n",
    "# Vectorize the text -- note the 0 outputs\n",
    "text_tfidf = text_dataset.map(vectorize_layer)\n",
    "for text in text_tfidf:\n",
    "  print(text)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T17:21:24.331523Z",
     "start_time": "2024-11-13T17:21:24.049460Z"
    }
   },
   "id": "bae2d66ec5af24c6"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1.3862944 0.        0.        0.       ], shape=(4,), dtype=float32)\n",
      "tf.Tensor([1.3862944 0.        0.        0.6931472], shape=(4,), dtype=float32)\n",
      "tf.Tensor([3.465736  0.        0.        0.6931472], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0.        0.6931472 0.        0.6931472], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0. 0. 0. 0.], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "new_dataset = tf.data.Dataset.from_tensor_slices([\n",
    "  \"bif bif\",\n",
    "  \"bif bar bif\",\n",
    "  \"bif bif bif bif bif bar\",\n",
    "  \"foo bar\",\n",
    "  \"\"\n",
    "])\n",
    "\n",
    "text_vectorized = new_dataset.map(vectorize_layer)\n",
    "for text in text_vectorized:\n",
    "  print(text)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T17:22:04.432658Z",
     "start_time": "2024-11-13T17:22:04.302399Z"
    }
   },
   "id": "7145b637a59eac50"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "84771048e0914ad6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# bigrams\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8815b886ef05c0f"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[UNK]', 'the', 'the mat', 'the cat', 'sat on', 'sat', 'on the', 'on', 'mat', 'cat sat', 'cat']\n"
     ]
    }
   ],
   "source": [
    "text_ds = tf.data.Dataset.from_tensor_slices([\"the cat sat on the mat\"])\n",
    "\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "  ngrams=2,\n",
    "  max_tokens=20000,\n",
    "  output_mode='multi_hot'\n",
    ")\n",
    "\n",
    "vectorize_layer.adapt(text_ds)\n",
    "print(vectorize_layer.get_vocabulary())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T17:23:30.629450Z",
     "start_time": "2024-11-13T17:23:30.513924Z"
    }
   },
   "id": "41e8778e9e8eeea4"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 1 1 1 1 1 1 1 1 1], shape=(11,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "text_bg = text_ds.map(vectorize_layer)\n",
    "for text in text_bg:\n",
    "  print(text)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T17:23:45.723958Z",
     "start_time": "2024-11-13T17:23:45.604199Z"
    }
   },
   "id": "c31f7c927989c4d3"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T17:23:09.572048Z",
     "start_time": "2024-11-13T17:23:09.551479Z"
    }
   },
   "id": "3f11b0c6e2ae0549"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T17:23:09.720081Z",
     "start_time": "2024-11-13T17:23:09.698459Z"
    }
   },
   "id": "4fb25fa37767a8ea"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T17:23:09.887517Z",
     "start_time": "2024-11-13T17:23:09.867687Z"
    }
   },
   "id": "838f75c0f09d7c42"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4769b798e4413b0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
