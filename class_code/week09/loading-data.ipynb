{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-21T03:45:20.114529Z",
     "start_time": "2024-10-21T03:45:17.897661Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-21T03:45:20.119982Z",
     "start_time": "2024-10-21T03:45:20.114198Z"
    }
   },
   "id": "a52947eae0382b35"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "num_classes = np.unique(y_test).size\n",
    "\n",
    "# from integers in [0,255] to float in [0,1]\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test  = X_test.astype('float32') / 255\n",
    "\n",
    "# store the labels in 1D arrays, not 2D\n",
    "y_train = np.squeeze(y_train)  # could do this with reshape\n",
    "y_test = np.squeeze(y_test)\n",
    "\n",
    "\n",
    "# Convert class vectors to one-hot encoded\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-21T03:45:21.294662Z",
     "start_time": "2024-10-21T03:45:20.116862Z"
    }
   },
   "id": "d2061acb43d665c8"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-21T03:45:21.296854Z",
     "start_time": "2024-10-21T03:45:21.294863Z"
    }
   },
   "id": "3fc2c05d80c1f9ca"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class DynamicSizeBatchGenerator(keras.utils.Sequence):\n",
    "  \"\"\" Generate batches that get smaller as training proceeds. \"\"\"\n",
    "\n",
    "  def __init__(self, X, y, *, start_size, end_size, num_epochs):\n",
    "    super().__init__()\n",
    "    self.X = X\n",
    "    self.y = y\n",
    "    self.start_size = start_size\n",
    "    self.end_size = end_size\n",
    "    self.num_epochs = num_epochs\n",
    "    self.current_epoch = 0\n",
    "    self.batch_size = start_size\n",
    "  \n",
    "  \n",
    "  \n",
    "  def __len__(self):\n",
    "    \"\"\" Return the number of batches that can be produced. \"\"\"\n",
    "    \n",
    "    # we can generate any number of batches, so provide a large number\n",
    "    return 1000000\n",
    "  \n",
    "  @staticmethod\n",
    "  def make_batch(X, y, batch_size):\n",
    "    \"\"\" Make a random batch. \"\"\"\n",
    "    \n",
    "    idx = np.random.choice(X.shape[0], batch_size)\n",
    "    return X[idx], y[idx]\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    \"\"\" Return a batch. \"\"\"\n",
    "    \n",
    "    # Generate the batch\n",
    "    return self.make_batch(self.X, self.y, self.batch_size)\n",
    "\n",
    "\n",
    "  def on_epoch_end(self):\n",
    "    \"\"\" Choose a different random subset of the data. \"\"\"\n",
    "    \n",
    "    self.current_epoch += self.current_epoch\n",
    "    self.batch_size = self.start_size + \\\n",
    "                      int(self.end_size * (self.current_epoch / self.num_epochs))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-21T03:45:21.304091Z",
     "start_time": "2024-10-21T03:45:21.299580Z"
    }
   },
   "id": "83b851e35ee75ebe"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "num_epochs = 15\n",
    "train_generator = DynamicSizeBatchGenerator(\n",
    "  X_train, y_train,\n",
    "  start_size=128, end_size=4,\n",
    "  num_epochs=num_epochs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-21T03:45:21.304185Z",
     "start_time": "2024-10-21T03:45:21.301817Z"
    }
   },
   "id": "fa7f0e4e77ae975e"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-20 20:45:21.308729: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Max\n",
      "2024-10-20 20:45:21.308762: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2024-10-20 20:45:21.308769: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2024-10-20 20:45:21.308785: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-10-20 20:45:21.308795: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2024-10-20 20:45:21.643645: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m500/500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 17ms/step - accuracy: 0.3927 - loss: 1.6802 - val_accuracy: 0.5752 - val_loss: 1.2073\n",
      "Epoch 2/15\n",
      "\u001B[1m500/500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 16ms/step - accuracy: 0.6054 - loss: 1.1340 - val_accuracy: 0.6199 - val_loss: 1.0870\n",
      "Epoch 3/15\n",
      "\u001B[1m500/500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 16ms/step - accuracy: 0.6656 - loss: 0.9692 - val_accuracy: 0.6481 - val_loss: 1.0190\n",
      "Epoch 4/15\n",
      "\u001B[1m500/500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 16ms/step - accuracy: 0.6981 - loss: 0.8800 - val_accuracy: 0.6777 - val_loss: 0.9510\n",
      "Epoch 5/15\n",
      "\u001B[1m500/500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 16ms/step - accuracy: 0.7232 - loss: 0.7993 - val_accuracy: 0.6805 - val_loss: 0.9419\n",
      "Epoch 6/15\n",
      "\u001B[1m500/500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 16ms/step - accuracy: 0.7532 - loss: 0.7246 - val_accuracy: 0.6840 - val_loss: 0.9571\n",
      "Epoch 7/15\n",
      "\u001B[1m500/500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 15ms/step - accuracy: 0.7789 - loss: 0.6526 - val_accuracy: 0.7021 - val_loss: 0.9086\n",
      "Epoch 8/15\n",
      "\u001B[1m500/500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 15ms/step - accuracy: 0.7964 - loss: 0.5954 - val_accuracy: 0.6975 - val_loss: 0.9520\n",
      "Epoch 9/15\n",
      "\u001B[1m500/500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 15ms/step - accuracy: 0.8183 - loss: 0.5327 - val_accuracy: 0.7067 - val_loss: 0.9442\n",
      "Epoch 10/15\n",
      "\u001B[1m500/500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 16ms/step - accuracy: 0.8421 - loss: 0.4678 - val_accuracy: 0.6935 - val_loss: 1.0057\n",
      "Epoch 11/15\n",
      "\u001B[1m500/500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 16ms/step - accuracy: 0.8621 - loss: 0.4085 - val_accuracy: 0.7048 - val_loss: 1.0039\n",
      "Epoch 12/15\n",
      "\u001B[1m500/500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 16ms/step - accuracy: 0.8820 - loss: 0.3590 - val_accuracy: 0.7018 - val_loss: 1.0759\n",
      "Epoch 13/15\n",
      "\u001B[1m500/500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 16ms/step - accuracy: 0.8952 - loss: 0.3176 - val_accuracy: 0.6944 - val_loss: 1.1217\n",
      "Epoch 14/15\n",
      "\u001B[1m500/500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 16ms/step - accuracy: 0.9104 - loss: 0.2712 - val_accuracy: 0.6842 - val_loss: 1.2264\n",
      "Epoch 15/15\n",
      "\u001B[1m500/500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 16ms/step - accuracy: 0.9250 - loss: 0.2346 - val_accuracy: 0.6967 - val_loss: 1.2635\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = keras.Sequential([\n",
    "  keras.layers.Input(shape=(32, 32, 3)),\n",
    "  keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(128, activation='relu'),\n",
    "  keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "  train_generator, \n",
    "  epochs=num_epochs,\n",
    "  steps_per_epoch=500, \n",
    "  batch_size=32,\n",
    "  validation_data=(X_test, y_test)\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-21T03:47:22.895799Z",
     "start_time": "2024-10-21T03:45:21.317603Z"
    }
   },
   "id": "b9ca3cdcd8e72577"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "{'accuracy': [0.48807811737060547,\n  0.620718777179718,\n  0.6732968688011169,\n  0.707156240940094,\n  0.7323125004768372,\n  0.7605156302452087,\n  0.785406231880188,\n  0.8020312786102295,\n  0.8264843821525574,\n  0.8483906388282776,\n  0.8657812476158142,\n  0.8845937252044678,\n  0.898812472820282,\n  0.9125937223434448,\n  0.9277499914169312],\n 'loss': [1.4356911182403564,\n  1.090832233428955,\n  0.9471660256385803,\n  0.8534831404685974,\n  0.7767249345779419,\n  0.7011699080467224,\n  0.637131929397583,\n  0.5771342515945435,\n  0.5132456421852112,\n  0.45047658681869507,\n  0.40002307295799255,\n  0.3470534682273865,\n  0.3082069158554077,\n  0.26369985938072205,\n  0.2253839522600174],\n 'val_accuracy': [0.5752000212669373,\n  0.6198999881744385,\n  0.6481000185012817,\n  0.6776999831199646,\n  0.6804999709129333,\n  0.6840000152587891,\n  0.7020999789237976,\n  0.6974999904632568,\n  0.7067000269889832,\n  0.6934999823570251,\n  0.704800009727478,\n  0.7017999887466431,\n  0.6944000124931335,\n  0.6841999888420105,\n  0.6966999769210815],\n 'val_loss': [1.2072550058364868,\n  1.0870434045791626,\n  1.018981695175171,\n  0.9509961009025574,\n  0.9419023394584656,\n  0.9571418762207031,\n  0.9086288213729858,\n  0.9520379900932312,\n  0.9442428946495056,\n  1.0056512355804443,\n  1.0039265155792236,\n  1.075908899307251,\n  1.121717929840088,\n  1.2263725996017456,\n  1.2635270357131958]}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-21T03:55:39.320846Z",
     "start_time": "2024-10-21T03:55:39.309912Z"
    }
   },
   "id": "a66aa18d26ff91c5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6ca67b53ee776090"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
